{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2530d817-6ae5-4887-9bfe-7d57f1d769eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from dataset import GeoEra5Dataset, GeoEra5Dataset40, GeoUkesmDataset100, SlpEra5Dataset, GeoUkesmDataset, SlpUkesmDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36503834-4ba1-4ce6-a01d-f8a2ea3fede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_geo_data = GeoEra5Dataset(prefix=\"../\")\n",
    "era5_geo_data40 = GeoEra5Dataset40(prefix=\"../\")\n",
    "era5_slp_data = SlpEra5Dataset(prefix=\"../\")\n",
    "ukesm_geo_data = GeoUkesmDataset(prefix=\"../\")\n",
    "ukesm_geo_data100 = GeoUkesmDataset100(prefix=\"../\")\n",
    "ukesm_slp_data = SlpUkesmDataset(prefix=\"../\")\n",
    "\n",
    "\n",
    "era5_geo_data.data = era5_geo_data.data.reshape(\n",
    "    len(era5_geo_data.data), int(era5_geo_data.data.size / len(era5_geo_data.data))\n",
    ")\n",
    "\n",
    "era5_geo_data40.data = era5_geo_data40.data.reshape(\n",
    "    len(era5_geo_data40.data), int(era5_geo_data40.data.size / len(era5_geo_data40.data))\n",
    ")\n",
    "\n",
    "era5_slp_data.data = era5_slp_data.data.reshape(\n",
    "    len(era5_slp_data.data), int(era5_slp_data.data.size / len(era5_slp_data.data))\n",
    ")\n",
    "\n",
    "ukesm_geo_data.data = ukesm_geo_data.data.reshape(\n",
    "    len(ukesm_geo_data.data), int(ukesm_geo_data.data.size / len(ukesm_geo_data.data))\n",
    ")\n",
    "\n",
    "ukesm_geo_data100.data = ukesm_geo_data100.data.reshape(\n",
    "    len(ukesm_geo_data100.data), int(ukesm_geo_data100.data.size / len(ukesm_geo_data100.data))\n",
    ")\n",
    "\n",
    "ukesm_slp_data.data = ukesm_slp_data.data.reshape(\n",
    "    len(ukesm_slp_data.data), int(ukesm_slp_data.data.size / len(ukesm_slp_data.data))\n",
    ")\n",
    "\n",
    "combined_geo_data = np.concatenate((ukesm_geo_data.data, era5_geo_data.data), axis=0)\n",
    "combined_geo_labels = np.concatenate((ukesm_geo_data.labels, era5_geo_data.labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45d0d40-68fd-493f-a18e-97b5cc21b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(verbose=1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 400],\n",
    "    \"max_depth\": [None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8],\n",
    "    \"bootstrap\": [True],\n",
    "    \"max_features\": [\"log2\"],\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_classifier, param_grid=param_grid, cv=10, scoring=[\"f1\", \"precision\", \"recall\"], refit=\"f1\", n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5479116-b8a4-4056-83c8-93593c767316",
   "metadata": {},
   "source": [
    "### era5 hyperparameter search with gridsearch cv (geopotential height)\n",
    "first 3 rows will be printed after finished training. the whole result can be downloaded in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77000721-89b1-4810-95a1-070a733163d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(era5_geo_data.data, era5_geo_data.labels)\n",
    "print(pd.DataFrame(grid_search.cv_results_).sort_values(\"rank_test_f1\").head(3).loc[:, [\"params\", \"mean_test_f1\", \"rank_test_f1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586ddd8d-03e6-436e-a5ae-d6fb4084770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).to_csv('grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c09c2-5227-4064-9b15-948a6782a374",
   "metadata": {},
   "source": [
    "### ukesm hyperparameter search with gridsearch cv (geopotential height)\n",
    "first 3 rows will be printed after finished training. the whole result can be downloaded in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5084de4-3774-4f41-a13e-974f4d392e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(ukesm_geo_data.data, ukesm_geo_data.labels)\n",
    "print(pd.DataFrame(grid_search.cv_results_).sort_values(\"rank_test_f1\").head(3).loc[:, [\"params\", \"mean_test_f1\", \"rank_test_f1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c68009a-0000-4459-af1a-47e63eb40eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).to_csv('grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c12bcf-0cfd-4267-afff-9d5efa097468",
   "metadata": {},
   "source": [
    "### ukesm + era5 hyperparameter search with gridsearch cv (geopotential height)\n",
    "first 3 rows will be printed after finished training. the whole result can be downloaded in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91126a28-9da5-4ae2-abba-279337c32fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(combined_geo_data, combined_geo_labels)\n",
    "print(pd.DataFrame(grid_search.cv_results_).sort_values(\"rank_test_f1\").head(3).loc[:, [\"params\", \"mean_test_f1\", \"rank_test_f1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa78935-1f71-4b1e-a1b8-89389294e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).to_csv('grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e7fb33",
   "metadata": {},
   "source": [
    "### era5 hyperparameter search with gridsearch cv (mean sea level pressure)\n",
    "first 3 rows will be printed after finished training. the whole result can be downloaded in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4265fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(era5_slp_data.data, era5_slp_data.labels)\n",
    "print(pd.DataFrame(grid_search.cv_results_).sort_values(\"rank_test_f1\").head(3).loc[:, [\"params\", \"mean_test_f1\", \"rank_test_f1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79aab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).to_csv('grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2b0813",
   "metadata": {},
   "source": [
    "### ukesm hyperparameter search with gridsearch cv (mean sea level pressure)\n",
    "first 3 rows will be printed after finished training. the whole result can be downloaded in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(era5_slp_data.data, era5_slp_data.labels)\n",
    "print(pd.DataFrame(grid_search.cv_results_).sort_values(\"rank_test_f1\").head(3).loc[:, [\"params\", \"mean_test_f1\", \"rank_test_f1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f314ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).to_csv('grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a862e6",
   "metadata": {},
   "source": [
    "## final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f7b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(folds, final_param_grid, data):\n",
    "    kf = KFold(n_splits=folds, shuffle=False)\n",
    "\n",
    "    full_labels = []\n",
    "    full_predictions = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(data.data)):    \n",
    "        train_dataset = data[train_index]\n",
    "        test_dataset = data[test_index]\n",
    "\n",
    "        rf = RandomForestClassifier(**final_param_grid)\n",
    "        rf.fit(train_dataset[0], train_dataset[1])\n",
    "\n",
    "        test_predictions = rf.predict(test_dataset[0])\n",
    "        full_predictions.extend(test_predictions)\n",
    "        full_labels.extend(test_dataset[1])\n",
    "\n",
    "        if fold % 10 == 0:\n",
    "            print(f\"on fold {fold+1} / {folds}\")\n",
    "            print(f\"fold {fold} f1: {f1_score(test_dataset[1], test_predictions)}\")\n",
    "\n",
    "    full_predictions = torch.tensor(full_predictions).long()\n",
    "\n",
    "    return (full_labels, full_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20078a0",
   "metadata": {},
   "source": [
    "## final training for era5\n",
    "first cell is training a yearly split with 41 iterations on the era5 dataset. in the second cell the transferability is tested with a 41 year training dataset on era5 data and a full 101 year test run on ukesm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d2976-dd02-4936-8eb1-115e244fd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_param_grid_geo = {\n",
    "    'bootstrap': True, \n",
    "    'max_depth': None, \n",
    "    'max_features': 'log2', \n",
    "    'min_samples_leaf': 4, \n",
    "    'min_samples_split': 5, \n",
    "    'n_estimators': 400\n",
    "}\n",
    "\n",
    "final_param_grid_slp = {\n",
    "    'bootstrap': True, \n",
    "    'max_depth': None, \n",
    "    'max_features': 'log2', \n",
    "    'min_samples_leaf': 1, \n",
    "    'min_samples_split': 5, \n",
    "    'n_estimators': 400\n",
    "}\n",
    "\n",
    "folds = 41\n",
    "\n",
    "geo_labels, geo_predictions = fit(folds, final_param_grid_geo, era5_geo_data)\n",
    "slp_labels, slp_predictions = fit(folds, final_param_grid_slp, era5_slp_data)\n",
    "\n",
    "print(\"FINAL METRICS GEO\")\n",
    "print(f\"f1: {f1_score(geo_labels, geo_predictions)}\")\n",
    "print(f\"precision: {precision_score(geo_labels, geo_predictions)}\")\n",
    "print(f\"recall: {recall_score(geo_labels, geo_predictions)}\")\n",
    "\n",
    "print(\"FINAL METRICS SLP\")\n",
    "print(f\"f1: {f1_score(slp_labels, slp_predictions)}\")\n",
    "print(f\"precision: {precision_score(slp_labels, slp_predictions)}\")\n",
    "print(f\"recall: {recall_score(slp_labels, slp_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf9f79-e347-44d7-8dae-debf6e11ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = era5_geo_data\n",
    "test_dataset = ukesm_geo_data\n",
    "\n",
    "transfer_rf = RandomForestClassifier(**final_param_grid_geo)\n",
    "transfer_rf.fit(train_dataset.data, train_dataset.labels)\n",
    "\n",
    "test_predictions = torch.tensor(transfer_rf.predict(test_dataset.data)).long()\n",
    "\n",
    "print(\"FINAL METRICS\")\n",
    "print(f\"f1: {f1_score(test_dataset.labels, test_predictions)}\")\n",
    "print(f\"precision: {precision_score(test_dataset.labels, test_predictions)}\")\n",
    "print(f\"recall: {recall_score(test_dataset.labels, test_predictions)}\")\n",
    "print(f\"percentage blocked: {(torch.bincount(test_predictions)[1] / len(test_predictions)) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346db37-955f-44d8-b58d-83e6d082ef1a",
   "metadata": {},
   "source": [
    "## final training for ukesm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f061e6-e233-4ffe-8297-4873c60e2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_param_grid_geo = {\n",
    "    'bootstrap': True, \n",
    "    'max_depth': None, \n",
    "    'max_features': 'log2', \n",
    "    'min_samples_leaf': 1, \n",
    "    'min_samples_split': 10, \n",
    "    'n_estimators': 400\n",
    "}\n",
    "\n",
    "final_param_grid_slp = {\n",
    "    'bootstrap': True, \n",
    "    'max_depth': None, \n",
    "    'max_features': 'log2', \n",
    "    'min_samples_leaf': 4, \n",
    "    'min_samples_split': 10, \n",
    "    'n_estimators': 200\n",
    "}\n",
    "\n",
    "folds = 50\n",
    "\n",
    "slp_labels, slp_predictions = fit(folds, final_param_grid_slp, ukesm_slp_data)\n",
    "geo_labels, geo_predictions = fit(folds, final_param_grid_geo, ukesm_geo_data)\n",
    "\n",
    "\n",
    "print(\"FINAL METRICS GEO\")\n",
    "print(f\"f1: {f1_score(geo_labels, geo_predictions)}\")\n",
    "print(f\"precision: {precision_score(geo_labels, geo_predictions)}\")\n",
    "print(f\"recall: {recall_score(geo_labels, geo_predictions)}\")\n",
    "\n",
    "print(\"FINAL METRICS SLP\")\n",
    "print(f\"f1: {f1_score(slp_labels, slp_predictions)}\")\n",
    "print(f\"precision: {precision_score(slp_labels, slp_predictions)}\")\n",
    "print(f\"recall: {recall_score(slp_labels, slp_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed25836-d390-4cc9-a095-8dfbda8313bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ukesm_geo_data\n",
    "test_dataset = era5_geo_data\n",
    "\n",
    "transfer_rf = RandomForestClassifier(**final_param_grid)\n",
    "transfer_rf.fit(train_dataset.data, train_dataset.labels)\n",
    "\n",
    "test_predictions = torch.tensor(transfer_rf.predict(test_dataset.data)).long()\n",
    "\n",
    "print(\"FINAL METRICS\")\n",
    "print(f\"f1: {f1_score(test_dataset.labels, test_predictions)}\")\n",
    "print(f\"precision: {precision_score(test_dataset.labels, test_predictions)}\")\n",
    "print(f\"recall: {recall_score(test_dataset.labels, test_predictions)}\")\n",
    "print(f\"percentage blocked: {(torch.bincount(test_predictions)[1] / len(test_predictions)) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b950934-0d46-48a0-94ca-0005936103bf",
   "metadata": {},
   "source": [
    "## final training for ukesm + era5 combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22b51d-e910-4f2e-afc8-0e184223c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "final_param_grid = {\n",
    "    'bootstrap': True, \n",
    "    'max_depth': None, \n",
    "    'max_features': 'log2', \n",
    "    'min_samples_leaf': 1, \n",
    "    'min_samples_split': 10, \n",
    "    'n_estimators': 200\n",
    "}\n",
    "\n",
    "# ERA5\n",
    "\n",
    "folds = 41\n",
    "kf = KFold(n_splits=folds, shuffle=False)\n",
    "\n",
    "full_labels = []\n",
    "full_predictions = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(era5_geo_data.data)):    \n",
    "    train_dataset = ConcatDataset((era5_geo_data[train_index], ukesm_geo_data))\n",
    "    test_dataset = era5_geo_data[test_index]\n",
    "\n",
    "    rf = RandomForestClassifier(**final_param_grid)\n",
    "    rf.fit(train_dataset[0], train_dataset[1])\n",
    "\n",
    "    test_predictions = rf.predict(test_dataset[0])\n",
    "    full_predictions.extend(test_predictions)\n",
    "    full_labels.extend(test_dataset[1])\n",
    "\n",
    "    if fold % 10 == 0:\n",
    "        print(f\"on fold {fold+1} / {folds}\")\n",
    "        print(f\"fold {fold} f1: {f1_score(test_dataset[1], test_predictions)}\")\n",
    "\n",
    "full_predictions = torch.tensor(full_predictions).long()\n",
    "\n",
    "print(\"FINAL METRICS ERA5\")\n",
    "print(f\"f1: {f1_score(full_labels, full_predictions)}\")\n",
    "print(f\"precision: {precision_score(full_labels, full_predictions)}\")\n",
    "print(f\"recall: {recall_score(full_labels, full_predictions)}\")\n",
    "print(f\"percentage blocked: {(torch.bincount(full_predictions)[1] / len(full_predictions)) * 100}%\")\n",
    "\n",
    "# UKESM\n",
    "\n",
    "folds = 101\n",
    "kf = KFold(n_splits=folds, shuffle=False)\n",
    "\n",
    "full_labels = []\n",
    "full_predictions = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(ukesm_geo_data.data)):    \n",
    "    train_dataset = ConcatDataset((ukesm_geo_data[train_index], era5_geo_data))\n",
    "    test_dataset = ukesm_geo_data[test_index]\n",
    "\n",
    "    rf = RandomForestClassifier(**final_param_grid)\n",
    "    rf.fit(train_dataset[0], train_dataset[1])\n",
    "\n",
    "    test_predictions = rf.predict(test_dataset[0])\n",
    "    full_predictions.extend(test_predictions)\n",
    "    full_labels.extend(test_dataset[1])\n",
    "\n",
    "    if fold % 10 == 0:\n",
    "        print(f\"on fold {fold+1} / {folds}\")\n",
    "        print(f\"fold {fold} f1: {f1_score(test_dataset[1], test_predictions)}\")\n",
    "\n",
    "full_predictions = torch.tensor(full_predictions).long()\n",
    "\n",
    "print(\"FINAL METRICS UKESM\")\n",
    "print(f\"f1: {f1_score(full_labels, full_predictions)}\")\n",
    "print(f\"precision: {precision_score(full_labels, full_predictions)}\")\n",
    "print(f\"recall: {recall_score(full_labels, full_predictions)}\")\n",
    "print(f\"percentage blocked: {(torch.bincount(full_predictions)[1] / len(full_predictions)) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3966d2-28d9-41a2-99ae-2df56b4f3bab",
   "metadata": {},
   "source": [
    "## visualizations for random forest algorithms\n",
    "set random forest to visualize in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b0c7feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from util import get_date\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "writer = SummaryWriter(f\"../runs_random_forest/{datetime.datetime.now().strftime('%Y-%m-%d_%H:%M')}\")\n",
    "random_forest = transfer_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84c3f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(data, time):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=5, ncols=1, subplot_kw={\"projection\": ccrs.PlateCarree()}\n",
    "    )\n",
    "\n",
    "    axs = axs.flatten()\n",
    "    clevs = np.arange(-1, 3, 0.5)\n",
    "    long = np.arange(-45, 55, 1)\n",
    "    lat = np.arange(30, 75, 1)\n",
    "\n",
    "    for i in range(5):\n",
    "        time = time + datetime.timedelta(days=1)\n",
    "        axs[i].coastlines(resolution=\"110m\", linewidth=1)\n",
    "        cs = axs[i].contourf(\n",
    "            long,\n",
    "            lat,\n",
    "            data[i],\n",
    "            clevs,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            cmap=plt.cm.RdBu_r,\n",
    "        )\n",
    "        if i == 0:\n",
    "            axs[i].set_title(str(time))\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.55, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(cs, cax=cbar_ax, orientation=\"vertical\")\n",
    "\n",
    "    plt.draw()\n",
    "\n",
    "    fig_np = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    fig_np = fig_np.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    fig_np = fig_np.transpose((2, 0, 1))\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0825203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukesm_predictions = random_forest.predict(ukesm_geo_data.data)\n",
    "era5_predictions = random_forest.predict(era5_geo_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1234dde-8562-44b2-8aa9-56a1354f74da",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ukesm_predictions\n",
    "dataset = ukesm_geo_data\n",
    "dataset_type = \"ukesm\"\n",
    "\n",
    "conf_matrix = confusion_matrix(dataset.labels, predictions)\n",
    "\n",
    "false_positives = (predictions == 1) & (dataset.labels == 0)\n",
    "false_negatives = (predictions == 0) & (dataset.labels == 1)\n",
    "\n",
    "print(\"false_positives: \" + str(conf_matrix[0][1]))\n",
    "print(\"false_negatives: \" + str(conf_matrix[1][0]))\n",
    "\n",
    "for idx, (fp, fn) in enumerate(zip(false_positives, false_negatives)):\n",
    "    date = get_date(dataset.time[idx], dataset_type)\n",
    "    if fp.item():\n",
    "        image = get_image(dataset.data[idx].reshape((5, 45, 100)), date)\n",
    "        writer.add_image(f\"false-positive/rf_{date.strftime('%Y-%m-%d')}\", image)\n",
    "    if fn.item():\n",
    "        image = get_image(dataset.data[idx].reshape((5, 45, 100)), date)\n",
    "        writer.add_image(f\"false-negative/rf_{date.strftime('%Y-%m-%d')}\", image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blocking",
   "language": "python",
   "name": "blocking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
