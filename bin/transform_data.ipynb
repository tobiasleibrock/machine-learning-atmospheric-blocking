{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"<var>\"\n",
    "lon, lat = \"<lon>\", \"<lat>\"\n",
    "data_path = \"../data/<path>\"\n",
    "label_path = \"../data/<path>\"\n",
    "output_path = \"../data/<path>\"\n",
    "data = xr.open_dataset(xr.backends.NetCDF4DataStore(Dataset(data_path, mode='r')), decode_times=True)\n",
    "labels = xr.open_dataset(xr.backends.NetCDF4DataStore(Dataset(label_path, mode='r')), decode_times=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De-Seasonalization\n",
    "\n",
    "the next code block is used to de-seasonalize the data according to the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a simplistic method to subtract the daily average values\n",
    "def deseasonalization(ds):\n",
    "    daily_climatology = ds.groupby('time.dayofyear').mean(dim='time')\n",
    "    window_size=10\n",
    "    ### make sure the circular nature of the data is recognized when taking the rolling mean\n",
    "    daily_climatology_circular = xr.concat([daily_climatology.isel(dayofyear=slice(-window_size//2, None)),\n",
    "                        daily_climatology,\n",
    "                        daily_climatology.isel(dayofyear=slice(None, window_size//2))],\n",
    "                        dim='dayofyear')\n",
    "    # smooth the daily data for the climatology, because it is noisy\n",
    "    daily_climatology_circular = daily_climatology_circular.rolling(dayofyear=10,center=True,min_periods=1).mean()\n",
    "    daily_climatology = daily_climatology_circular.isel(dayofyear=slice(window_size//2,-window_size//2))\n",
    "    # Subtract the daily climatology from the original data to get deseasonalized data\n",
    "    ds_deseasonalized = ds - daily_climatology.sel(dayofyear=ds.time.dt.dayofyear)\n",
    "    return ds_deseasonalized\n",
    "    \n",
    "### deaseasonalize and then divide by the respective standard deviation\n",
    "data = deseasonalization(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De-Trending\n",
    "\n",
    "the next code block is used to de-trend the data according to the thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detrending(dataset):\n",
    "    x = np.arange(len(dataset.time))\n",
    "    mean = np.mean(dataset[variable].to_numpy(), axis=(1,2))\n",
    "    coef = np.polyfit(x, mean, 1)\n",
    "    poly1d_fn = np.poly1d(coef)\n",
    "    \n",
    "    poly_array = np.array([np.full((len(dataset[lat]), len(dataset[lon])), poly1d_fn(x)) for x in range(len(dataset.time))])\n",
    "    detrended_ds = dataset - poly_array\n",
    "    return detrended_ds\n",
    "\n",
    "# Assuming data is an xarray dataset with a 'time' dimension\n",
    "data = detrending(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "the data is normalized using the standard deviation. this calculates a similar score to z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[variable].data = data[variable].data/np.std(data[variable].data,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Period Transformation\n",
    "\n",
    "the data is transformed into (time, 5, 45, 100) samples to allow blocking detection on each individual data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(output_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "extended_data = np.concatenate([data[variable][:], data[variable][:4]], axis=0)\n",
    "\n",
    "data = data.assign(\n",
    "    z=(\n",
    "        [\"time\", \"day_range\", \"lat\", \"lon\"],\n",
    "        [\n",
    "            np.array(extended_data[i : i + 5])\n",
    "            for i in range(len(extended_data) - 4)\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "data.to_netcdf(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
